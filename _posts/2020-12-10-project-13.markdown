---
layout: default
modal-id: 14
date: 2020-12-09
img: stitchedImage.png
alt: image-alt
project-date: December 2020
description: <h2>Breif Overview</h2> The primary motivation with this work is to replicate some of the simulation research work carried out in Prof. Malcolm's Maclver's neuroscience lab on actual animals. The lab has primarily been working on predator prey experiments in simulation and published results on the same. In order to verify that some of these results carry over to the results on actual animal, a maze space was setup and a mice is allowed to run inside the maze where it tries to reach a goal position while a robot acts a predator and threatens the mice. In order to make these things a reality, a high speed mice tracking system at more than 100 fps at least is needed since the robot needs to  plan online to take up the predator role. Since the total area is about 200 cm x 200 cm, the pixel / mm required for imaging the mice satisfactorily demands the need of using multiple cameras and therefore, a need to do multiview image stitching to stitch the image from camera view naturally emerged. <h2> Hardware Setup </h2> The hardware setup consists of 4 Basler Ace cameras powered by PoCL cables and connected to the computer systems through PCIe framegrabbers. The camera are mounted on above the maze at an approximate height of about 90 cms above the ground using 80/20 frames. The cameras are mounted on the 80 / 20 frames using mounting adapters and T-slots. The system also has a GTX 1050 Ti GPU card for running CUDA enabled computer vision algorithms and deep learning algorithms. The cameras are capable of running at max fps of 187 while the frame grabbers can support their max speed with a highest speed of 400 fps. All of camera parameters were tuned for high speed image capture. In particular, binning was used to utilize the max speed but the downside is that each camera's resolution reduced to 1024 x 1024 from their original 2048 x 2048 resolution. But this was okay and necessary for our application. The cameras run in free-running mode since at such high speed captures, synchronization between cameras wasn't a big concern<div style="display:flex"> <div style="flex:1;padding-right:5px;"> <img src="./img/portfolio/hardware.png" width="140" class="left"> </div> <div style="flex:1;padding-left:5px;"> <img src="./img/portfolio/maze.jpg" width="200" class="left"> </div></div> <h2> Image Stitching </h2> The homography of each camera to the ground plane was determined by using a charuco board and this predetermined homographies were used to stitch the images from 4 camera views together. To keep the post short, all details related to the image stitching is not discussed here. To know in depth details about it please visit my <a href="https://senthillihtnes1994.medium.com/multi-view-image-stitching-based-on-the-pre-calibrated-camera-homographies-991e1fe8a6f4" target="_blank">daily medium blog post</a> The stitched image obtained from the pipeline is shown below. <br><br> <img src="./img/portfolio/stitchedImage2.png" class="center" width="560"> <br><br> <h2> High speed mice tracking </h2> To accomplish high speed mice tracking, I tried out a few strategies namely Object tracking and Background Subtraction. Since mice and robot are the only moving objects in the camera view, these two objects can be identified through background subtraction. The robot is placed with a tag and hence, its position is identified and any dynamic movement corresponding to the robot can be disassociated by locating the position of the tag and the position of the mice can be found by background subtraction. Each cell present in the image is manually labeled and this gives a mechanism for associated the mice position with a cell and this result is superimposed on the stitched image. <br><br> <img src="./img/portfolio/bg_ouput.gif" class="center" width="560"> <br><br> For doing more useful offline analysis, I trained a model for tracking the pose of the mice using deeplabcut. This model is obtained by taking the pre-trained deepercut model trained on human pose estimation task and doing a transfer learning with mice data obtained from real experiments. This model is a useful offline tool for analyzing mice behavior. In the video we can see that three mice body parts are tracked cleanly.<iframe width="560" height="315" src="https://www.youtube.com/embed/Tws1cs8wtmQ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br><br> The model training and inference code is in python and the whole pipeline is in C++ and therefore to facilitate their integration, I also wrote a interface script based on pybind11 that can run the deeplabcut inference code through the python interpretor in C++ <h2> Parallelism in the overall architecture </h2> The whole architecture was heavily parallelized so that the experiments can be conducted online while at the same time logging videos for future reference. In general following were the requirements from the pipeline <ul><li> Online mice tracking at very high fps (> 100) </li> <li> Ability to log raw videos for future analysis </li> <li> Ability to stitch videos and log the stitched video for future analysis </li></ul> In order accomplish this, the code was heavily multi-threading, thereby utilizing all the cores in the system. std::asyc function in C++ was the primary mechanism used for parallelism. The pipeline has around 13 asynchronous threads that run all the time. The description of each thread is given below <ul><li>The main action (mice tracking using background subtraction) happens on the main thread at a very high speed </li> <li> 4 slower threads write all the raw acquired images to a video </li> <li> 1 thread constructs a stitched image from the 4 cameras</li> <li> 2-3 sub-threads are utilized by the image stitching thread for transferring pixels </li> <li> Another 4 threads track the robot position</li></li> Hence, in total, around 13 asynchronous threads run in parallel. The following two images show the CPU utilization.<br> <img src="./img/portfolio/CPU_1.png" width="1200" class="left"> <br><br> <img src="./img/portfolio/CPU_2.png" width="1200" class="left"> <br><br> The system has 4 cores with intel's 2 hyperthreads per core, there is a total of 8 virtual cores. It can be seen from the images that all the cores are fully utilized and that the back_ground_subt process takes around 7 cores while one core is utilized by system process. Since more than 13 threads run in these 7 virtual cores on average, the overall application slows down a little but the lab is planning to shift towards a more powerful processor thereby utilizing the parallelism fully. The final speeds achieved for various tasks within the system are shown below <ul><li> Image capture and mice tracking using background subtraction at more than 100 fps </li><li> Raw Video writing at around 30 fps </li> <li> Stitched image writing at around 10 fps</li></ul> The code for this project can be found at <a href="https://github.com/senthilpalanisamy/Camera_tracking" target="_blank">my github repo</a> 
title: High speed image stitching and mice tracking 

---
